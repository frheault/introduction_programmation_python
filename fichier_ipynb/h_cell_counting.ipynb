{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comptage automatique de cellules\n",
    "\n",
    "Ce chapitre présente des techniques avancées pour compter automatiquement des cellules dans des images de microscopie. Le comptage manuel est fastidieux et sujet aux erreurs, d'où l'intérêt de méthodes automatisées.\n",
    "\n",
    "Nous explorerons :\n",
    "-   L'analyse des canaux RGB pour optimiser le contraste\n",
    "-   Le calcul du rapport signal/bruit (SNR) pour évaluer la qualité\n",
    "-   Les techniques de seuillage (manuel et automatique)\n",
    "-   La détection de maxima locaux pour identifier les centres cellulaires\n",
    "-   La segmentation avancée avec l'algorithme de watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the RGB channels for best contrast\n",
    "\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import imageio as iio\n",
    "import nibabel as nib\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils import summarize_intensities\n",
    "\n",
    "FILENAME = './cells.png'\n",
    "cell_arr = iio.imread(FILENAME)[:, :, 0:3]\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "im = axs[0].imshow(cell_arr)\n",
    "\n",
    "R_arr = cell_arr.copy()\n",
    "R_arr[:,:,1:3] = 0\n",
    "im = axs[1].imshow(R_arr)\n",
    "\n",
    "G_arr = cell_arr.copy()\n",
    "G_arr[:,:,0:3:2] = 0\n",
    "im = axs[2].imshow(G_arr)\n",
    "\n",
    "B_arr = cell_arr.copy()\n",
    "B_arr[:,:,0:2] = 0\n",
    "im = axs[3].imshow(B_arr)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Analyse des canaux RGB\n",
    "\n",
    "Pour optimiser la détection, nous devons identifier quel canal (Rouge, Vert, Bleu) offre le meilleur contraste entre les cellules et l'arrière-plan.\n",
    "\n",
    "**Stratégie** :\n",
    "-   Visualiser chaque canal séparément\n",
    "-   Comparer leur contraste visuel\n",
    "-   Sélectionner le canal offrant la meilleure distinction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the RGB channels for best contrast\n",
    "\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import imageio as iio\n",
    "import nibabel as nib\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils import summarize_intensities\n",
    "\n",
    "FILENAME = './cells.png'\n",
    "cell_arr = iio.imread(FILENAME)[:, :, 0:3]\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "im = axs[0].imshow(cell_arr)\n",
    "\n",
    "R_arr = cell_arr.copy()\n",
    "R_arr[:,:,1:3] = 0\n",
    "im = axs[1].imshow(R_arr)\n",
    "\n",
    "G_arr = cell_arr.copy()\n",
    "G_arr[:,:,0:3:2] = 0\n",
    "im = axs[2].imshow(G_arr)\n",
    "\n",
    "B_arr = cell_arr.copy()\n",
    "B_arr[:,:,0:2] = 0\n",
    "im = axs[3].imshow(B_arr)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Calcul du rapport signal/bruit (SNR)\n",
    "\n",
    "Le SNR quantifie la qualité de l'image en comparant la variabilité du signal (cellules) au bruit de fond :\n",
    "\n",
    "$$SNR = \\sqrt{\\frac{\\sigma_{signal}}{\\sigma_{bruit}}}$$\n",
    "\n",
    "**Méthode** :\n",
    "-   Sélection manuelle de deux régions : une avec des cellules, une sans\n",
    "-   Calcul de l'écart-type dans chaque région\n",
    "-   Un SNR élevé indique une bonne qualité d'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SNR for each channel (and mean/max)\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def compute_snr_v2(data, corner_s, size_s, corner_n, size_n):\n",
    "    patch_s = data[corner_s[1]:corner_s[1]+size_s[1], corner_s[0]:corner_s[0]+size_s[0]]\n",
    "    patch_n = data[corner_n[1]:corner_n[1]+size_n[1], corner_n[0]:corner_n[0]+size_n[0]]\n",
    "    \n",
    "    std_s = np.std(patch_s)\n",
    "    std_n = np.std(patch_n)\n",
    "\n",
    "    return np.sqrt(std_s/std_n), patch_s, patch_n\n",
    "\n",
    "# Manually found for this specific image\n",
    "CORNER_S = (1, 90)\n",
    "SIZE_S = (35, 25)\n",
    "CORNER_N = (40, 75)\n",
    "SIZE_N = (50, 40)\n",
    "\n",
    "titles = ['Red', 'Green', 'Blue', 'Mean', 'Max']\n",
    "# Fake 3D\n",
    "max_arr = np.max(cell_arr, axis=-1).astype(np.uint8)\n",
    "\n",
    "fig, axs = plt.subplots(5, 3, figsize=(12, 20))\n",
    "for i, arr in enumerate([R_arr, G_arr, B_arr, mean_arr, max_arr]):\n",
    "    # The last 2 are in 2D (one channel)\n",
    "    if i > 2:\n",
    "        arr = arr[0:200, 0:200]\n",
    "    else:\n",
    "        arr = arr[0:200, 0:200, :]\n",
    "\n",
    "    im = axs[i, 0].imshow(arr)\n",
    "    axs[i, 0].set_title(titles[i])\n",
    "    divider = make_axes_locatable(axs[i, 0])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    \n",
    "    # The last 2 are in 2D (one chann\n",
    "    if i > 2:\n",
    "        snr, patch_s, patch_n = compute_snr_v2(arr[:, :], CORNER_S, SIZE_S,\n",
    "                                             CORNER_N, SIZE_N)\n",
    "    else:\n",
    "        snr, patch_s, patch_n = compute_snr_v2(arr[:, :, i], CORNER_S, SIZE_S,\n",
    "                                             CORNER_N, SIZE_N)\n",
    "    n, bins, patches = axs[i, 1].hist(patch_s.ravel(), 50, density=True, facecolor='g', alpha=0.75)\n",
    "    axs[i, 0].add_patch(Rectangle(CORNER_S, SIZE_S[0], SIZE_S[1],\n",
    "                              edgecolor='orange',\n",
    "                              facecolor='none',\n",
    "                              lw=2))\n",
    "    n, bins, patches = axs[i, 2].hist(patch_n.ravel(), 50, density=True, facecolor='g', alpha=0.75)\n",
    "    axs[i, 0].add_patch(Rectangle(CORNER_N, SIZE_N[0], SIZE_N[1],\n",
    "                                  edgecolor='pink',\n",
    "                                  facecolor='none',\n",
    "                                  lw=2))\n",
    "#     iio.imwrite('s_{}.png'.format(titles[i]), patch_s)\n",
    "#     iio.imwrite('n_{}.png'.format(titles[i]), patch_n)\n",
    "    print(titles[i], snr)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Seuillage manuel basé sur les percentiles\n",
    "\n",
    "Le seuillage permet de créer un masque binaire séparant les cellules de l'arrière-plan :\n",
    "-   **Percentiles** : Seuil basé sur la distribution des intensités (25%, 50%, 75%)\n",
    "-   **Comparaison visuelle** : Test de différents seuils sur chaque canal\n",
    "-   **Objectif** : Trouver le seuil qui isole au mieux les cellules\n",
    "\n",
    "Cette approche permet d'initialiser les algorithmes plus sophistiqués."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Red', 'Green', 'Blue', 'Mean', 'Max']\n",
    "# Fake 3D\n",
    "mean_arr = np.mean(cell_arr, axis=-1).astype(np.uint8)\n",
    "max_arr = np.max(cell_arr, axis=-1).astype(np.uint8)\n",
    "\n",
    "# Guess a good threshold to initialize the algorithm\n",
    "fig, axs = plt.subplots(3, 5, figsize=(12, 6))\n",
    "for i, arr in enumerate([R_arr, G_arr, B_arr, mean_arr, max_arr]):\n",
    "    for j, val in enumerate([25, 50, 75]):\n",
    "        if i > 2:\n",
    "            arr = arr[0:200, 0:200]\n",
    "            tmp = arr.copy()\n",
    "        else:\n",
    "            arr = arr[0:200, 0:200, :]\n",
    "            tmp = np.sum(arr, axis=-1).copy()\n",
    "        tmp[tmp > np.percentile(tmp, val)] = 255\n",
    "        tmp[tmp < np.percentile(tmp, val)] = 0\n",
    "        im = axs[j, i].imshow(tmp)\n",
    "        axs[j, i].set_title(titles[i])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Détection automatique du seuil avec les mélanges gaussiens\n",
    "\n",
    "Au lieu de deviner le seuil, on peut le détecter automatiquement en modélisant l'histogramme :\n",
    "-   **Gaussian Mixture Model (GMM)** : Décompose l'histogramme en 2 gaussiennes\n",
    "-   **Composante 1** : Arrière-plan (intensités faibles)\n",
    "-   **Composante 2** : Cellules (intensités élevées)\n",
    "-   **Seuil optimal** : À l'intersection des deux distributions\n",
    "\n",
    "Cette méthode est robuste et reproductible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically detecting a threshold can be used instead of guessing\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import norm\n",
    "\n",
    "cell_arr = np.sum(R_arr, axis=-1).astype(float)\n",
    "\n",
    "cell_mask = np.zeros(cell_arr.shape)\n",
    "cell_mask[cell_arr > np.percentile(cell_arr, 50)] = 1\n",
    "n, bins, patches = plt.hist(cell_arr[cell_mask > 0], 50, density=True, facecolor='g', alpha=0.75)\n",
    "X = np.expand_dims(cell_arr[cell_mask > 0], axis=-1)\n",
    "gm = GaussianMixture(n_components=2, random_state=0).fit(X)\n",
    "\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 1000)\n",
    "mu = gm.means_[0, 0]\n",
    "std = np.sqrt(gm.covariances_[0, 0, 0])\n",
    "p = norm.pdf(x, mu, std)\n",
    "  \n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "print(\"Fit Values: {:.2f} and {:.2f}\".format(mu, std))\n",
    "\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 1000)\n",
    "mu = gm.means_[1, 0]\n",
    "std = np.sqrt(gm.covariances_[1, 0, 0]) + 0.5\n",
    "p = norm.pdf(x, mu, std)\n",
    "  \n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "print(\"Fit Values: {:.2f} and {:.2f}\".format(mu, std))\n",
    "\n",
    "\n",
    "# print(X)\n",
    "# print(gm.means_[1, 0], gm.covariances_[1, 0, 0])\n",
    "# x = np.linspace(0, len(n), 1000)\n",
    "# plt.plot(x, norm.pdf(x, gm.means_[0, 0], gm.covariances_[0, 0, 0]))\n",
    "# plt.plot(x, norm.pdf(x, gm.means_[1, 0], gm.covariances_[1, 0, 0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Détection des centres cellulaires (maxima locaux)\n",
    "\n",
    "Pour compter les cellules, nous devons localiser leur centre :\n",
    "-   **Filtre gaussien** : Lissage pour réduire le bruit\n",
    "-   **Maxima locaux** : Pixels plus brillants que tous leurs voisins\n",
    "-   **K-means** : Clustering pour délimiter chaque cellule autour de son centre\n",
    "\n",
    "**Workflow** :\n",
    "1. Appliquer le seuil pour créer un masque\n",
    "2. Détecter les maxima locaux (centres potentiels)\n",
    "3. Utiliser K-means pour segmenter les régions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the center of each cell using a peak_filter (local maxima)\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def peak_filter(data, win_size=5, blur=5):\n",
    "    # Blurring an image can help to increase SNR and avoid extreme case\n",
    "    data_copy = gaussian_filter(data, sigma=5)\n",
    "    indices = np.nonzero(data)\n",
    "    len_indices = len(np.nonzero(data)[0])\n",
    "    \n",
    "    new_data = np.zeros(data.shape)\n",
    "    count = 1\n",
    "    for i in range(len_indices):\n",
    "        # Check bound!\n",
    "        x, y = (indices[0][i], indices[1][i])\n",
    "        x_min = x-win_size\n",
    "        x_max = x+win_size+1\n",
    "        y_min = y-win_size\n",
    "        y_max = y+win_size+1\n",
    "        \n",
    "        if x_min < 0:\n",
    "            x_min = 0\n",
    "        if x_max >= data.shape[0]:\n",
    "            x_min = data.shape[0] - 1\n",
    "        if y_min < 0:\n",
    "            y_min = 0\n",
    "        if y_max >= data.shape[1]:\n",
    "            y_min = data.shape[1] - 1\n",
    "        \n",
    "        # Look around each pixel to see if the current coordinate is a local maxima\n",
    "        neighborhood = data_copy[x_min:x_max, y_min:y_max]\n",
    "        if data_copy[x,y] == np.max(neighborhood):\n",
    "            new_data[x,y] = count\n",
    "            count += 1\n",
    "    print('{} peaks were found!'.format(count-1))\n",
    "    return new_data\n",
    "\n",
    "def clusters_cells(peaks, mask):\n",
    "    # Using our peaks detection, launch a k-means algorithm with this initialisation to find each blob\n",
    "    labels = np.zeros(mask.shape, dtype=np.uint16)\n",
    "    X = np.argwhere(mask)\n",
    "    init_coord = np.argwhere(peaks)\n",
    "    kmeans = KMeans(n_clusters=np.count_nonzero(peaks), init=init_coord, random_state=0).fit(X)\n",
    "    for i in range(len(X)):\n",
    "        coord = tuple(X[i])\n",
    "        labels[coord] = kmeans.labels_[i]\n",
    "\n",
    "    return labels, kmeans.cluster_centers_\n",
    "\n",
    "# From earlier mixtures, use the threshold to accelerate computation (remove the vast majority of pixel)\n",
    "mu = gm.means_[0, 0]\n",
    "std = np.sqrt(gm.covariances_[0, 0, 0])\n",
    "\n",
    "cell_mask = cell_arr.copy()\n",
    "threshold = mu - 1*std\n",
    "cell_mask[cell_mask < threshold] = 0\n",
    "cell_mask[cell_mask >= threshold] = 1\n",
    "\n",
    "cell_arr *= cell_mask\n",
    "peaks_labels = peak_filter(cell_arr)\n",
    "labelled_regions, centers = clusters_cells(peaks_labels, cell_mask)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(20, 20))\n",
    "ax[0].imshow(cell_arr)\n",
    "ax[0].set_title('Original')\n",
    "ax[1].imshow(gaussian_filter(cell_arr, sigma=5))\n",
    "ax[1].set_title('Blur')\n",
    "ax[2].imshow(labelled_regions)\n",
    "ax[2].set_title('Labelled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Nettoyage morphologique des labels\n",
    "\n",
    "La segmentation initiale peut contenir des trous (pixels manquants à l'intérieur des cellules) :\n",
    "-   **`binary_closing()`** : Remplit les petits trous\n",
    "-   **Traitement par label** : Applique l'opération à chaque cellule individuellement\n",
    "-   **Visualisation** : Overlay des labels sur l'image originale\n",
    "\n",
    "Cela améliore la cohérence spatiale des régions segmentées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_closing, binary_opening, binary_erosion, binary_dilation\n",
    "\n",
    "def clean_up_labels(data):\n",
    "    # Tries to remove hole (empty pixel in cells)\n",
    "    new_data = np.zeros(data.shape)\n",
    "    for i in np.unique(data)[1:]:\n",
    "        tmp = np.zeros(data.shape)\n",
    "        tmp[data == i] = 1\n",
    "        tmp = binary_closing(tmp, iterations=3)\n",
    "        new_data[tmp > 0] = i\n",
    "    return new_data\n",
    "\n",
    "cleaned_labels = clean_up_labels(labelled_regions)\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(20, 20))\n",
    "ax[0].imshow(mean_arr, cmap='gray')\n",
    "ax[0].set_title('Original')\n",
    "ax[1].imshow(cleaned_labels, interpolation='nearest', cmap='tab20')\n",
    "ax[1].set_title('Cleaned')\n",
    "ax[2].imshow(mean_arr, cmap='gray')\n",
    "ax[2].imshow(cleaned_labels, interpolation='nearest', cmap='tab20', alpha=0.25)\n",
    "ax[2].set_title('Overlay')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Seuillage automatique avec Multi-Otsu\n",
    "\n",
    "La méthode d'Otsu est un standard pour le seuillage automatique :\n",
    "-   **Multi-Otsu** : Extension pour détecter plusieurs classes (3 ici)\n",
    "-   **Classes** : Arrière-plan, cellules normales, cellules en division\n",
    "-   **`filters.threshold_multiotsu()`** : Calcul automatique des seuils optimaux\n",
    "\n",
    "Cette méthode est plus simple et souvent plus robuste que le GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "from skimage import color, feature, filters, measure, morphology, segmentation, util\n",
    "\n",
    "# Import a function to simply do the gaussian mixture\n",
    "thresholds = filters.threshold_multiotsu(cell_arr, classes=3)\n",
    "regions = np.digitize(cell_arr, bins=thresholds)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax[0].imshow(cell_arr)\n",
    "ax[0].set_title('Original')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(regions)\n",
    "ax[1].set_title('Multi-Otsu thresholding')\n",
    "ax[1].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Segmentation par Watershed\n",
    "\n",
    "L'algorithme de watershed est optimal pour séparer des objets qui se touchent :\n",
    "\n",
    "**Principe** :\n",
    "1. **Transformation de distance** : Calcule la distance de chaque pixel au fond\n",
    "2. **Détection de maxima** : Identifie les pics de distance (centres cellulaires)\n",
    "3. **Watershed** : \"Inonde\" l'image en partant des pics pour délimiter les frontières\n",
    "\n",
    "**Avantages** :\n",
    "-   Sépare efficacement les cellules qui se touchent\n",
    "-   Implémentation optimisée dans scikit-image\n",
    "-   Résultats reproductibles\n",
    "\n",
    "Cette méthode est la plus professionnelle et robuste pour le comptage cellulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The library does it faster, better and a lot easier to use!\n",
    "# But my code is very close!\n",
    "\n",
    "cells = cell_arr > thresholds[0]\n",
    "dividing = mean_arr > thresholds[1]\n",
    "labeled_cells = measure.label(cells)\n",
    "labeled_dividing = measure.label(dividing)\n",
    "naive_mi = labeled_dividing.max() / labeled_cells.max()\n",
    "\n",
    "distance = ndi.distance_transform_edt(cells)\n",
    "\n",
    "local_max_coords = feature.peak_local_max(distance, min_distance=7)\n",
    "local_max_mask = np.zeros(distance.shape, dtype=bool)\n",
    "local_max_mask[tuple(local_max_coords.T)] = True\n",
    "markers = measure.label(local_max_mask)\n",
    "\n",
    "segmented_cells = segmentation.watershed(-distance, markers, mask=cells)\n",
    "print('{} peaks were found!'.format(len(np.unique(segmented_cells)[1:])))\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(10, 5))\n",
    "ax[0].imshow(cells, cmap='gray')\n",
    "ax[0].set_title('Overlapping nuclei')\n",
    "ax[1].imshow(color.label2rgb(segmented_cells, bg_label=0))\n",
    "ax[1].set_title('Segmented nuclei')\n",
    "color_labels = color.label2rgb(segmented_cells, mean_arr, alpha=0.4, bg_label=0)\n",
    "ax[2].imshow(color.label2rgb(segmented_cells, bg_label=0))\n",
    "ax[2].set_title('Labels Overlay')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}